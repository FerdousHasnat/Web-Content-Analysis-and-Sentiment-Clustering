{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "787cc1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permission to crawl https://concordia.ca : True\n",
      "https://concordia.ca\n",
      "https://concordia.ca/offices.html\n",
      "https://concordia.ca/offices/facilities.html\n",
      "https://concordia.ca/artsci/applied-human-sciences.html\n",
      "https://concordia.ca/about/history.html\n",
      "https://concordia.ca/web/accessibility.html\n",
      "https://concordia.ca/maps/buildings/pc.html\n",
      "https://concordia.ca/artsci/applied-human-sciences/about/jobs.html\n",
      "https://concordia.ca/alumni-friends.html\n",
      "https://concordia.ca/artsci/alumni.html\n",
      "https://concordia.ca/research/composites.html\n",
      "https://concordia.ca/cce.html\n",
      "https://concordia.ca/academics/experiential-learning.html\n",
      "https://concordia.ca/cuevents/offices/provost/otsenhakta/2023/11/30/indigenous-holiday-market.html\n",
      "https://concordia.ca/ginacody/ciadi.html\n",
      "https://concordia.ca/artsci/english.html\n",
      "https://concordia.ca/academics/online-courses.html\n",
      "https://concordia.ca/jmsb/about/departments/marketing.html\n",
      "https://concordia.ca/research/for-researchers.html\n",
      "https://concordia.ca/research/polanyi.html\n",
      "https://concordia.ca/artsci/applied-human-sciences/programs/graduate.html\n",
      "https://concordia.ca/provost.html\n",
      "https://concordia.ca/content/concordia/en/students/financial/employment/jobs\n",
      "https://concordia.ca/alumni-friends/benefits-services/off-campus.html\n",
      "https://concordia.ca/finearts/design.html\n",
      "https://concordia.ca/health.html\n",
      "https://concordia.ca/artsci/english/research/mordecai-richler-reading-room.html\n",
      "https://concordia.ca/cunews/jmsb/2023/11/13/concordia-marketing-prof-appointed-lifetime-member-of-the-royal-society-of-canada.html\n",
      "https://concordia.ca/research/for-researchers/federal-support.html\n",
      "https://concordia.ca#content_main_tabs-0-collapse\n",
      "Total amount of documents processed: 30\n",
      "Running clustering with k=3\n",
      "Top terms per cluster:\n",
      "Cluster 0:\n",
      "workshops - 0.000000\n",
      "digital - 0.000000\n",
      "register - 0.000000\n",
      "concordia - 0.000000\n",
      "courses - 0.000000\n",
      "marketing - 0.000000\n",
      "corporate - 0.000000\n",
      "training - 0.000000\n",
      "english - 0.000000\n",
      "stay - 0.000000\n",
      "hours - 0.000000\n",
      "january - 0.000000\n",
      "testing - 0.000000\n",
      "language - 0.000000\n",
      "continuing - 0.000000\n",
      "services - 0.000000\n",
      "cce - 0.000000\n",
      "celpip - 0.000000\n",
      "workplace - 0.000000\n",
      "fit - 1.000000\n",
      "cael - 0.000000\n",
      "ielts - 0.000000\n",
      "great - 3.000000\n",
      "programs - 0.000000\n",
      "winter - 0.000000\n",
      "frequently - 0.000000\n",
      "practical - 0.000000\n",
      "newsletter - 0.000000\n",
      "education - 0.000000\n",
      "fb - 0.000000\n",
      "industry - 0.000000\n",
      "asked - 0.000000\n",
      "diploma - 0.000000\n",
      "new - 0.000000\n",
      "school - 0.000000\n",
      "calendar - 0.000000\n",
      "learning - 0.000000\n",
      "communications - 0.000000\n",
      "questions - 0.000000\n",
      "knowledge - 0.000000\n",
      "work - 0.000000\n",
      "previous - 0.000000\n",
      "university - 0.000000\n",
      "business - 0.000000\n",
      "fr - 0.000000\n",
      "expend - 0.000000\n",
      "test - 0.000000\n",
      "colleges - 0.000000\n",
      "514 - 0.000000\n",
      "848 - 0.000000\n",
      "Cluster 0 sentiment score: 4.000000\n",
      "Cluster 1:\n",
      "concordia - 0.000000\n",
      "department - 0.000000\n",
      "human - 0.000000\n",
      "alumni - 0.000000\n",
      "university - 0.000000\n",
      "services - 0.000000\n",
      "graduate - 0.000000\n",
      "arts - 0.000000\n",
      "science - 0.000000\n",
      "faculty - 0.000000\n",
      "applied - 0.000000\n",
      "sciences - 0.000000\n",
      "school - 0.000000\n",
      "calendar - 0.000000\n",
      "programs - 0.000000\n",
      "2023 - 0.000000\n",
      "giving - 0.000000\n",
      "writing - 0.000000\n",
      "student - 0.000000\n",
      "english - 0.000000\n",
      "campus - 0.000000\n",
      "richler - 0.000000\n",
      "montreal - 0.000000\n",
      "academic - 0.000000\n",
      "resources - 0.000000\n",
      "events - 0.000000\n",
      "expend - 0.000000\n",
      "news - 0.000000\n",
      "opportunities - 2.000000\n",
      "class - 0.000000\n",
      "schools - 0.000000\n",
      "colleges - 0.000000\n",
      "514 - 0.000000\n",
      "job - 0.000000\n",
      "studies - 0.000000\n",
      "848 - 0.000000\n",
      "undergraduate - 0.000000\n",
      "creative - 2.000000\n",
      "mordecai - 0.000000\n",
      "ve - 0.000000\n",
      "search - 0.000000\n",
      "contact - 0.000000\n",
      "life - 0.000000\n",
      "site - 0.000000\n",
      "prevention - 0.000000\n",
      "links - 0.000000\n",
      "safety - 1.000000\n",
      "time - 0.000000\n",
      "support - 2.000000\n",
      "departments - 0.000000\n",
      "Cluster 1 sentiment score: 7.000000\n",
      "Cluster 2:\n",
      "concordia - 0.000000\n",
      "research - 0.000000\n",
      "services - 0.000000\n",
      "university - 0.000000\n",
      "school - 0.000000\n",
      "academic - 0.000000\n",
      "campus - 0.000000\n",
      "students - 0.000000\n",
      "calendar - 0.000000\n",
      "graduate - 0.000000\n",
      "student - 0.000000\n",
      "resources - 0.000000\n",
      "arts - 0.000000\n",
      "science - 0.000000\n",
      "centre - 0.000000\n",
      "links - 0.000000\n",
      "admissions - 0.000000\n",
      "events - 0.000000\n",
      "faculty - 0.000000\n",
      "health - 0.000000\n",
      "schools - 0.000000\n",
      "media - 0.000000\n",
      "quick - 0.000000\n",
      "undergraduate - 0.000000\n",
      "news - 0.000000\n",
      "expend - 0.000000\n",
      "class - 0.000000\n",
      "colleges - 0.000000\n",
      "international - 0.000000\n",
      "office - 0.000000\n",
      "new - 0.000000\n",
      "education - 0.000000\n",
      "2023 - 0.000000\n",
      "units - 0.000000\n",
      "business - 0.000000\n",
      "support - 2.000000\n",
      "studies - 0.000000\n",
      "safety - 1.000000\n",
      "montreal - 0.000000\n",
      "john - 0.000000\n",
      "848 - 0.000000\n",
      "514 - 0.000000\n",
      "prevention - 0.000000\n",
      "site - 0.000000\n",
      "search - 0.000000\n",
      "molson - 0.000000\n",
      "opportunities - 2.000000\n",
      "institute - 0.000000\n",
      "study - 0.000000\n",
      "dept - 0.000000\n",
      "Cluster 2 sentiment score: 5.000000\n",
      "Running clustering with k=6\n",
      "Top terms per cluster:\n",
      "Cluster 0:\n",
      "parking - 0.000000\n",
      "suite - 0.000000\n",
      "perform - 0.000000\n",
      "campus - 0.000000\n",
      "including - 0.000000\n",
      "equipment - 0.000000\n",
      "people - 0.000000\n",
      "disease - -1.000000\n",
      "houses - 0.000000\n",
      "loyola - 0.000000\n",
      "groups - 0.000000\n",
      "concordia - 0.000000\n",
      "healthy - 2.000000\n",
      "range - 0.000000\n",
      "sgw - 0.000000\n",
      "school - 0.000000\n",
      "research - 0.000000\n",
      "lung - 0.000000\n",
      "novel - 2.000000\n",
      "cardiopulmonary - 0.000000\n",
      "balance - 0.000000\n",
      "welcoming - 0.000000\n",
      "athletic - 0.000000\n",
      "windows - 0.000000\n",
      "laboratories - 0.000000\n",
      "ct - 0.000000\n",
      "outdoor - 0.000000\n",
      "chronic - 0.000000\n",
      "ages - 0.000000\n",
      "imaging - 0.000000\n",
      "interior - 0.000000\n",
      "permits - 0.000000\n",
      "students - 0.000000\n",
      "indoor - 0.000000\n",
      "area - 0.000000\n",
      "buildings - 0.000000\n",
      "natural - 1.000000\n",
      "machines - 0.000000\n",
      "clinical - 0.000000\n",
      "heart - 0.000000\n",
      "sleep - 0.000000\n",
      "light - 0.000000\n",
      "street - 0.000000\n",
      "allows - 0.000000\n",
      "athletes - 0.000000\n",
      "individuals - 0.000000\n",
      "advances - 0.000000\n",
      "calendar - 0.000000\n",
      "services - 0.000000\n",
      "health - 0.000000\n",
      "Cluster 0 sentiment score: 4.000000\n",
      "Cluster 1:\n",
      "concordia - 0.000000\n",
      "services - 0.000000\n",
      "university - 0.000000\n",
      "research - 0.000000\n",
      "academic - 0.000000\n",
      "school - 0.000000\n",
      "campus - 0.000000\n",
      "calendar - 0.000000\n",
      "graduate - 0.000000\n",
      "students - 0.000000\n",
      "arts - 0.000000\n",
      "student - 0.000000\n",
      "science - 0.000000\n",
      "resources - 0.000000\n",
      "links - 0.000000\n",
      "centre - 0.000000\n",
      "faculty - 0.000000\n",
      "admissions - 0.000000\n",
      "events - 0.000000\n",
      "quick - 0.000000\n",
      "expend - 0.000000\n",
      "schools - 0.000000\n",
      "media - 0.000000\n",
      "undergraduate - 0.000000\n",
      "health - 0.000000\n",
      "news - 0.000000\n",
      "class - 0.000000\n",
      "colleges - 0.000000\n",
      "new - 0.000000\n",
      "international - 0.000000\n",
      "support - 2.000000\n",
      "education - 0.000000\n",
      "units - 0.000000\n",
      "alumni - 0.000000\n",
      "business - 0.000000\n",
      "montreal - 0.000000\n",
      "514 - 0.000000\n",
      "848 - 0.000000\n",
      "safety - 1.000000\n",
      "opportunities - 2.000000\n",
      "john - 0.000000\n",
      "site - 0.000000\n",
      "prevention - 0.000000\n",
      "office - 0.000000\n",
      "2023 - 0.000000\n",
      "search - 0.000000\n",
      "molson - 0.000000\n",
      "studies - 0.000000\n",
      "marketing - 0.000000\n",
      "study - 0.000000\n",
      "Cluster 1 sentiment score: 5.000000\n",
      "Cluster 2:\n",
      "department - 0.000000\n",
      "concordia - 0.000000\n",
      "human - 0.000000\n",
      "applied - 0.000000\n",
      "graduate - 0.000000\n",
      "sciences - 0.000000\n",
      "university - 0.000000\n",
      "programs - 0.000000\n",
      "arts - 0.000000\n",
      "services - 0.000000\n",
      "writing - 0.000000\n",
      "english - 0.000000\n",
      "faculty - 0.000000\n",
      "richler - 0.000000\n",
      "student - 0.000000\n",
      "school - 0.000000\n",
      "calendar - 0.000000\n",
      "science - 0.000000\n",
      "2023 - 0.000000\n",
      "ve - 0.000000\n",
      "creative - 2.000000\n",
      "design - 0.000000\n",
      "mordecai - 0.000000\n",
      "academic - 0.000000\n",
      "life - 0.000000\n",
      "undergraduate - 0.000000\n",
      "time - 0.000000\n",
      "resources - 0.000000\n",
      "campus - 0.000000\n",
      "events - 0.000000\n",
      "colleges - 0.000000\n",
      "class - 0.000000\n",
      "schools - 0.000000\n",
      "job - 0.000000\n",
      "opportunities - 2.000000\n",
      "news - 0.000000\n",
      "514 - 0.000000\n",
      "848 - 0.000000\n",
      "montreal - 0.000000\n",
      "positions - 0.000000\n",
      "research - 0.000000\n",
      "studies - 0.000000\n",
      "inquiries - 0.000000\n",
      "reading - 0.000000\n",
      "223 - 0.000000\n",
      "room - 0.000000\n",
      "ext - 0.000000\n",
      "ahsc - 0.000000\n",
      "youth - 0.000000\n",
      "expend - 0.000000\n",
      "Cluster 2 sentiment score: 4.000000\n",
      "Cluster 3:\n",
      "el - 0.000000\n",
      "benefits - 2.000000\n",
      "increased - 1.000000\n",
      "learning - 0.000000\n",
      "experiential - 0.000000\n",
      "concordia - 0.000000\n",
      "partners - 0.000000\n",
      "students - 0.000000\n",
      "doing - 0.000000\n",
      "practice - 0.000000\n",
      "employers - 0.000000\n",
      "university - 0.000000\n",
      "school - 0.000000\n",
      "knowledge - 0.000000\n",
      "learn - 0.000000\n",
      "faculty - 0.000000\n",
      "student - 0.000000\n",
      "help - 2.000000\n",
      "enhanced - 0.000000\n",
      "benefit - 2.000000\n",
      "work - 0.000000\n",
      "based - 0.000000\n",
      "engagement - 0.000000\n",
      "newsletter - 0.000000\n",
      "ways - 0.000000\n",
      "graduates - 0.000000\n",
      "experience - 0.000000\n",
      "industry - 0.000000\n",
      "better - 2.000000\n",
      "calendar - 0.000000\n",
      "science - 0.000000\n",
      "arts - 0.000000\n",
      "resources - 0.000000\n",
      "services - 0.000000\n",
      "opportunities - 2.000000\n",
      "operative - 0.000000\n",
      "impact - 0.000000\n",
      "institute - 0.000000\n",
      "gm - 0.000000\n",
      "staff - 0.000000\n",
      "class - 0.000000\n",
      "schools - 0.000000\n",
      "2023 - 0.000000\n",
      "international - 0.000000\n",
      "society - 0.000000\n",
      "apply - 0.000000\n",
      "integrated - 0.000000\n",
      "education - 0.000000\n",
      "team - 0.000000\n",
      "community - 0.000000\n",
      "Cluster 3 sentiment score: 11.000000\n",
      "Cluster 4:\n",
      "dept - 0.000000\n",
      "centre - 0.000000\n",
      "institute - 0.000000\n",
      "office - 0.000000\n",
      "concordia - 0.000000\n",
      "president - 0.000000\n",
      "studies - 0.000000\n",
      "vice - 0.000000\n",
      "research - 0.000000\n",
      "engineering - 0.000000\n",
      "theatre - 0.000000\n",
      "human - 0.000000\n",
      "school - 0.000000\n",
      "services - 0.000000\n",
      "student - 0.000000\n",
      "jmsb - 0.000000\n",
      "arts - 0.000000\n",
      "art - 0.000000\n",
      "science - 0.000000\n",
      "education - 0.000000\n",
      "management - 0.000000\n",
      "jewish - 0.000000\n",
      "students - 0.000000\n",
      "association - 0.000000\n",
      "graduate - 0.000000\n",
      "canadian - 0.000000\n",
      "college - 0.000000\n",
      "communications - 0.000000\n",
      "computer - 0.000000\n",
      "public - 0.000000\n",
      "international - 0.000000\n",
      "university - 0.000000\n",
      "sustainability - 1.000000\n",
      "career - 0.000000\n",
      "society - 0.000000\n",
      "academic - 0.000000\n",
      "digital - 0.000000\n",
      "political - 0.000000\n",
      "applied - 0.000000\n",
      "group - 0.000000\n",
      "community - 0.000000\n",
      "energy - 0.000000\n",
      "systems - 0.000000\n",
      "health - 0.000000\n",
      "sensory - 0.000000\n",
      "irish - 0.000000\n",
      "biology - 0.000000\n",
      "rights - 0.000000\n",
      "store - 0.000000\n",
      "dance - 0.000000\n",
      "Cluster 4 sentiment score: 1.000000\n",
      "Cluster 5:\n",
      "concordia - 0.000000\n",
      "alumni - 0.000000\n",
      "giving - 0.000000\n",
      "university - 0.000000\n",
      "magazine - 0.000000\n",
      "services - 0.000000\n",
      "friends - 0.000000\n",
      "2023 - 0.000000\n",
      "code - 0.000000\n",
      "tickets - 0.000000\n",
      "benefits - 2.000000\n",
      "portraits - 0.000000\n",
      "graduation - 0.000000\n",
      "expend - 0.000000\n",
      "recognition - 2.000000\n",
      "campus - 0.000000\n",
      "promo - 0.000000\n",
      "applause - 2.000000\n",
      "networks - 0.000000\n",
      "career - 0.000000\n",
      "calendar - 0.000000\n",
      "school - 0.000000\n",
      "publications - 0.000000\n",
      "50 - 0.000000\n",
      "concordians - 0.000000\n",
      "events - 0.000000\n",
      "arts - 0.000000\n",
      "home - 0.000000\n",
      "students - 0.000000\n",
      "conversation - 0.000000\n",
      "news - 0.000000\n",
      "skimax - 0.000000\n",
      "alouettes - 0.000000\n",
      "resources - 0.000000\n",
      "media - 0.000000\n",
      "ca - 0.000000\n",
      "montreal - 0.000000\n",
      "update - 0.000000\n",
      "advancement - 0.000000\n",
      "regular - 0.000000\n",
      "colleges - 0.000000\n",
      "academic - 0.000000\n",
      "class - 0.000000\n",
      "science - 0.000000\n",
      "search - 0.000000\n",
      "graduate - 0.000000\n",
      "schools - 0.000000\n",
      "join - 1.000000\n",
      "st - 0.000000\n",
      "support - 2.000000\n",
      "Cluster 5 sentiment score: 9.000000\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen, Request\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from afinn import Afinn\n",
    "\n",
    "import urllib.robotparser\n",
    "import math\n",
    "\n",
    "\n",
    "# Returns true if user crawler can fetch the URL, false otherwise\n",
    "def can_crawl(url):\n",
    "    try:\n",
    "        rp = urllib.robotparser.RobotFileParser()\n",
    "        if url.endswith('/'):\n",
    "            rp.set_url(url + 'robots.txt')\n",
    "            robot_txt = url + 'robots.txt'\n",
    "            rp.read()\n",
    "        else:\n",
    "            rp.set_url(url + '/robots.txt')\n",
    "            robot_txt = url + '/robots.txt'\n",
    "            rp.read()\n",
    "\n",
    "        print(\"Permission to crawl \" + str(url) + \" : \" + str(rp.can_fetch('*', robot_txt)))\n",
    "\n",
    "        if rp.can_fetch('*', robot_txt):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Something went wrong reading the robots.txt file...\")\n",
    "        return False\n",
    "\n",
    "\n",
    "# Takes in a URL and returns all hyperlink html tags \"a\"\n",
    "def visit_url(url):\n",
    "    try:\n",
    "        req = Request(url)\n",
    "        page = urlopen(req).read()\n",
    "        soup = BeautifulSoup(page, 'html.parser')\n",
    "        return soup.find_all('a')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Request failed\")\n",
    "        return []\n",
    "\n",
    "\n",
    "# Extracts links from the provided URL for a total of n files\n",
    "# Returns set of URLs visited\n",
    "def extract_links(url, n):\n",
    "    counter = 0\n",
    "    visited_list = set()\n",
    "    open_list = {url}\n",
    "\n",
    "    while len(open_list) > 0 and counter < n:\n",
    "        link = open_list.pop()\n",
    "        print(link)\n",
    "        new_links = visit_url(link)\n",
    "        visited_list.add(link)\n",
    "\n",
    "        counter = counter + 1\n",
    "\n",
    "        for l in new_links:\n",
    "            try:\n",
    "                file_name = l['href']\n",
    "\n",
    "                # Making sure only given host is scraped\n",
    "                if file_name.startswith('http') and not file_name.startswith(url):\n",
    "                    continue\n",
    "\n",
    "                if file_name.startswith('mailto') or file_name.startswith('tel'):\n",
    "                    continue\n",
    "\n",
    "                url_new = file_name\n",
    "\n",
    "                if not file_name.startswith(url):\n",
    "                    url_new = url + file_name\n",
    "\n",
    "                if url_new not in visited_list:\n",
    "                    open_list.add(url_new)\n",
    "\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "    return visited_list\n",
    "\n",
    "\n",
    "# Takes in a set of URLs and returns their text content\n",
    "def read_urls(urls):\n",
    "    documents = []\n",
    "    for url in urls:\n",
    "        try:\n",
    "            req = Request(url)\n",
    "            page = urlopen(req).read()\n",
    "            soup = BeautifulSoup(page, 'html.parser')\n",
    "            [s.extract() for s in soup(['style', 'script', '[document]', 'head', 'title'])]\n",
    "\n",
    "            # Remove excessive white spaces from text\n",
    "            doc = re.sub(r'\\s+', ' ', soup.get_text())\n",
    "\n",
    "            # Remove URLs from text\n",
    "            doc = re.sub(r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)', '', doc)\n",
    "            documents.append(doc)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Something went wrong reading the URLs - \" + str(e))\n",
    "            pass\n",
    "\n",
    "    # print(documents)\n",
    "    print(\"Total amount of documents processed: \" + str(len(documents)))\n",
    "\n",
    "    return documents\n",
    "\n",
    "\n",
    "# Takes list of documents to perform clustering and sentiment analysis operations on.\n",
    "# k number of clusters\n",
    "# 50 iterations\n",
    "# Sentiment analysis for each cluster is calculated by taking the 15 most popular words in each cluster\n",
    "# and averaging the sentiment score\n",
    "def perform_k_means_clustering_and_sentiment_analysis(docs, k):\n",
    "    afinn = Afinn()\n",
    "\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    X = vectorizer.fit_transform(docs)\n",
    "    model = KMeans(n_clusters=k, init='k-means++', max_iter=50, n_init=1)\n",
    "    model.fit(X)\n",
    "\n",
    "    print(\"Top terms per cluster:\")\n",
    "    ordered_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "    try:\n",
    "        terms = vectorizer.get_feature_names_out()  # Changed from get_feature_names to get_feature_names_out\n",
    "    except Exception as e:\n",
    "        print(\"Error getting feature names: \", e)\n",
    "        return  # Exit the function if terms cannot be retrieved\n",
    "\n",
    "    for i in range(k):\n",
    "        sentiment_score = 0\n",
    "        print(\"Cluster %d:\" % i)\n",
    "\n",
    "        for index in ordered_centroids[i, :50]:  # Print and score the top 50 terms, or as many as are available\n",
    "            if index < len(terms):  # Check if the index is within the range of the 'terms' list\n",
    "                term = terms[index]\n",
    "                term_score = afinn.score(term)\n",
    "                print('%s - %f' % (term, term_score))\n",
    "                sentiment_score += term_score\n",
    "            else:\n",
    "                break  # Break the loop if there are no more terms to process\n",
    "\n",
    "        print(\"Cluster %d sentiment score: %f\" % (i, sentiment_score))\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Please ensure link is of format 'http(s)://[host]'\n",
    "    url = \"https://concordia.ca\"\n",
    "\n",
    "    if can_crawl(url):\n",
    "        docs = read_urls(extract_links(url, 30))\n",
    "        \n",
    "        # First run with k=3\n",
    "        print(\"Running clustering with k=3\")\n",
    "        perform_k_means_clustering_and_sentiment_analysis(docs, 3)\n",
    "\n",
    "        # Second run with k=6\n",
    "        print(\"Running clustering with k=6\")\n",
    "        perform_k_means_clustering_and_sentiment_analysis(docs, 6)\n",
    "\n",
    "    else:\n",
    "        print(\"Cannot crawl \" + str(url) + \". Terminating ... \")\n",
    "        exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fe0802a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permission to crawl https://concordia.ca : True\n",
      "https://concordia.ca\n",
      "https://concordia.ca/about/community/office/projects/streets-cafe.html\n",
      "https://concordia.ca/contact.html\n",
      "https://concordia.ca/offices/ci.html\n",
      "https://concordia.ca/news/media-relations.html\n",
      "https://concordia.ca/admissions/undergraduate.html\n",
      "https://concordia.ca/maps/sgw-campus.html\n",
      "https://concordia.ca/admissions/undergraduate/quebec.html\n",
      "https://concordia.ca/about/administration-governance/president.html#tuition\n",
      "https://concordia.ca/web/terms.html\n",
      "https://concordia.ca/news/media-relations/team/patrick-lejtenyi.html#releases\n",
      "https://concordia.ca/fr/admission/etudes-au-1er-cycle.html\n",
      "https://concordia.ca/content/concordia/en/students/financial\n",
      "https://concordia.ca/research/chairs.html\n",
      "https://concordia.ca/students/financial/tuition-fees.html\n",
      "https://concordia.ca/coronavirus.html\n",
      "https://concordia.ca/news/stories/2023/12/05/workplace-culture-is-preventing-men-from-taking-paternity-leave-writes-claudine-mangen.html\n",
      "https://concordia.ca/faculty.html.html?fpid=steve-shih\n",
      "https://concordia.ca/cunews/main/stories/2023/11/15/update-on-2023-24-budget.html\n",
      "https://concordia.ca/fr/admission/etudes-au-1er-cycle/demande-admission.html\n",
      "https://concordia.ca/offices/ci/visiting-researchers.html\n",
      "https://concordia.ca/students.html\n",
      "https://concordia.ca/admissions/undergraduate/welcometours.html#chat\n",
      "https://concordia.ca#hcurc\n",
      "https://concordia.ca/international/partnerships.html\n",
      "https://concordia.ca/web/a-z.html\n",
      "https://concordia.ca/students/undergraduate.html\n",
      "https://concordia.ca/admissions/undergraduate/requirements/mature-entry.html\n",
      "https://concordia.ca/finearts/art-history.html\n",
      "https://concordia.ca/gradstudies/funding.html\n",
      "Total amount of documents processed: 30\n",
      "Top terms per cluster:\n",
      "Top terms per cluster:\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen, Request\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from afinn import Afinn\n",
    "\n",
    "import urllib.robotparser\n",
    "import math\n",
    "\n",
    "\n",
    "# Returns true if user crawler can fetch the URL, false otherwise\n",
    "def can_crawl(url):\n",
    "    try:\n",
    "        rp = urllib.robotparser.RobotFileParser()\n",
    "        if url.endswith('/'):\n",
    "            rp.set_url(url + 'robots.txt')\n",
    "            robot_txt = url + 'robots.txt'\n",
    "            rp.read()\n",
    "        else:\n",
    "            rp.set_url(url + '/robots.txt')\n",
    "            robot_txt = url + '/robots.txt'\n",
    "            rp.read()\n",
    "\n",
    "        print(\"Permission to crawl \" + str(url) + \" : \" + str(rp.can_fetch('*', robot_txt)))\n",
    "\n",
    "        if rp.can_fetch('*', robot_txt):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Something went wrong reading the robots.txt file...\")\n",
    "        return False\n",
    "\n",
    "\n",
    "# Takes in a URL and returns all hyperlink html tags \"a\"\n",
    "def visit_url(url):\n",
    "    try:\n",
    "        req = Request(url)\n",
    "        page = urlopen(req).read()\n",
    "        soup = BeautifulSoup(page, 'html.parser')\n",
    "        return soup.find_all('a')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Request failed\")\n",
    "        return []\n",
    "\n",
    "\n",
    "# Extracts links from the provided URL for a total of n files\n",
    "# Returns set of URLs visited\n",
    "def extract_links(url, n):\n",
    "    counter = 0\n",
    "    visited_list = set()\n",
    "    open_list = {url}\n",
    "\n",
    "    while len(open_list) > 0 and counter < n:\n",
    "        link = open_list.pop()\n",
    "        print(link)\n",
    "        new_links = visit_url(link)\n",
    "        visited_list.add(link)\n",
    "\n",
    "        counter = counter + 1\n",
    "\n",
    "        for l in new_links:\n",
    "            try:\n",
    "                file_name = l['href']\n",
    "\n",
    "                # Making sure only given host is scraped\n",
    "                if file_name.startswith('http') and not file_name.startswith(url):\n",
    "                    continue\n",
    "\n",
    "                if file_name.startswith('mailto') or file_name.startswith('tel'):\n",
    "                    continue\n",
    "\n",
    "                url_new = file_name\n",
    "\n",
    "                if not file_name.startswith(url):\n",
    "                    url_new = url + file_name\n",
    "\n",
    "                if url_new not in visited_list:\n",
    "                    open_list.add(url_new)\n",
    "\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "    return visited_list\n",
    "\n",
    "\n",
    "# Takes in a set of URLs and returns their text content\n",
    "def read_urls(urls):\n",
    "    documents = []\n",
    "    for url in urls:\n",
    "        try:\n",
    "            req = Request(url)\n",
    "            page = urlopen(req).read()\n",
    "            soup = BeautifulSoup(page, 'html.parser')\n",
    "            [s.extract() for s in soup(['style', 'script', '[document]', 'head', 'title'])]\n",
    "\n",
    "            # Remove excessive white spaces from text\n",
    "            doc = re.sub(r'\\s+', ' ', soup.get_text())\n",
    "\n",
    "            # Remove URLs from text\n",
    "            doc = re.sub(r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)', '', doc)\n",
    "            documents.append(doc)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Something went wrong reading the URLs - \" + str(e))\n",
    "            pass\n",
    "\n",
    "    # print(documents)\n",
    "    print(\"Total amount of documents processed: \" + str(len(documents)))\n",
    "\n",
    "    return documents\n",
    "\n",
    "def perform_k_means_clustering_and_sentiment_analysis(docs, k, file_name):\n",
    "    afinn = Afinn()\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    X = vectorizer.fit_transform(docs)\n",
    "    model = KMeans(n_clusters=k, init='k-means++', max_iter=50, n_init=1)\n",
    "    model.fit(X)\n",
    "\n",
    "    print(\"Top terms per cluster:\")\n",
    "    ordered_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "    terms = vectorizer.get_feature_names_out()\n",
    "\n",
    "    with open(file_name, 'w') as file:\n",
    "        for i in range(k):\n",
    "            file.write(f\"Cluster {i}:\\n\")\n",
    "            for index in ordered_centroids[i, :20]:  # Capture top 20 terms\n",
    "                term = terms[index]\n",
    "                file.write(f\"{term}\\n\")\n",
    "            file.write(\"\\n\")\n",
    "if __name__ == '__main__':\n",
    "    url = \"https://concordia.ca\"\n",
    "\n",
    "    if can_crawl(url):\n",
    "        docs = read_urls(extract_links(url, 30))\n",
    "        \n",
    "        # Clustering with k=3 and writing to a file\n",
    "        perform_k_means_clustering_and_sentiment_analysis(docs, 3, \"cluster_3_terms.txt\")\n",
    "\n",
    "        # Clustering with k=6 and writing to a file\n",
    "        perform_k_means_clustering_and_sentiment_analysis(docs, 6, \"cluster_6_terms.txt\")\n",
    "\n",
    "    else:\n",
    "        print(\"Cannot crawl \" + str(url) + \". Terminating ... \")\n",
    "        exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85df6973",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
